# Goal

>
í”„ë¡œë©”í…Œìš°ìŠ¤ Alert ì‹œìŠ¤í…œì„ êµ¬ì¶•í•œë‹¤.

AlertManager ë°°í¬ í›„ í…ŒìŠ¤íŠ¸ê¹Œì§€ ì§„í–‰í•œë‹¤.

# Index

1. Slack ì„¤ì •
2. AlertManager êµ¬ì„±í•˜ê¸° 1 - Node Labeling
3. AlertManager êµ¬ì„±í•˜ê¸° 1 - writing comfigMap
4. AlertManager êµ¬ì„±í•˜ê¸° 1 - writing rules
5. Trouble 1 - ìƒê°ë„ ëª»í•œ ì—ëŸ¬: zsh
6. Trouble 2 - CrashLoopBackOff
7. Trouble 3 - ë­ê°€ ë¬¸ì œì¸ì§€ ëª¨ë¥´ê² ì§€ë§Œ ì•ŒëŒì´ ì‘ë™í•˜ì§€ ì•ŠëŠ”ë‹¤. values.yml ê°ˆì•„ ì—ê¸°
8. Alering ì‘ë™ ì„±ê³µ, í…ŒìŠ¤íŠ¸
9. Trouble 4 - slack webhookì€ ë˜ì§€ ì•ŠìŒ
10. í…ŒìŠ¤íŠ¸ ì„±ê³µ. ì‹œê°„ì´ ê±¸ë¦° ìš”ì¸ ë¶„ì„



# 1. Slack ì„¤ì •
>
alert messageë¥¼ ë°›ì„ ì•±ìœ¼ë¡œëŠ” Slackì„ ì„ íƒí•œë‹¤.

1. slack worksapce ë° ì±„ë„ ìƒì„±

2. worksapceì—ì„œ ì„¤ì • ë° ê´€ë¦¬ -> ì•± ê´€ë¦¬

3. ê²€ìƒ‰ì°½ì— ìˆ˜ì‹  ì›¹ í›… ê²€ìƒ‰ -> slackì— ì¶”ê°€
![](https://velog.velcdn.com/images/hyunshoon/post/7eca59cf-9ff0-4b17-90e0-2cf300e5b613/image.png)

4. ì›¹ í›… ë°›ì„ ì±„ë„ ì§€ì • -> ì›¹í›… URL ë©”ëª¨


Slackì—ì„œì˜ ì´ˆê¸° ì„¤ì •ì€ ë

# AlertManager êµ¬ì„±í•˜ê¸°

## 2. êµ¬ì„±í•˜ê¸° ì „ Node labeling

### Why?
>
í”„ë¡œë©”í…Œìš°ìŠ¤ ì»´í¬ë„ŒíŠ¸ë“¤ì„ ë§ˆìŠ¤í„° ë…¸ë“œì— ë„ìš°ê¸° ìœ„í•¨.
Worker ë…¸ë“œì—ëŠ” ë‹¤ë¥¸ íŒŒë“œë“¤ì´ ì˜¬ë¼ê°„ë‹¤. ê·¸ë ‡ê¸° ë•Œë¬¸ì— íŠ¹ì • ìƒí™©ì—ì„œëŠ” ì›Œì»¤ë…¸ë“œì— ë§ì€ íŒŒë“œë“¤ì´ ì˜¬ë¼ê°€ë©° ë…¸ë“œì˜ ë¶ˆì•ˆì •ì„±ì´ ì»¤ì§ˆ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— í”„ë¡œë©”í…Œìš°ìŠ¤ ì»´í¬ë„ŒíŠ¸ë¥¼ ë§ˆìŠ¤í„° ë…¸ë“œì— ë„ìš´ë‹¤.

### Label ì„¤ì •

ì¿ ë²„ë„¤í‹°ìŠ¤ëŠ” ë…¸ë“œë¥¼ ë¼ë²¨ë¡œ ê´€ë¦¬í•  ìˆ˜ ìˆë‹¤.

1. label ì¡°íšŒ

`kubectl get nodes --show-labels`

2. nodeì— label ì¶”ê°€

`kubectl label nodes [node_name] [key]=[value]`
```
kubectl label nodes ip-10-0-3-65.ap-northeast-2.compute.internal key=worker
kubectl label nodes ip-10-0-3-70.ap-northeast-2.compute.internal key=worker
kubectl label nodes ip-10-0-3-181.ap-northeast-2.compute.internal key=master
```


## 3. alertmanager configmap  ì‘ì„±

alertmanager ì„¤ì •ì„ ì»¨í”¼ê·¸ë§µìœ¼ë¡œ ë§Œë“ ë‹¤.

`vi alert-notifier.yaml`

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  annotations:
    meta.helm.sh/release-name: prometheus
    meta.helm.sh/release-namespace: default
  labels:
    app: prometheus
    app.kubernetes.io/managed-by: Helm
    chart: prometheus-16.0.0
    component: alertmanager
    heritage: Helm
    release: prometheus
  name: prometheus-notifier-config
  namespace: default
data:
  alertmanager.yml: |
    global:
      slack_api_url: Slack-URL #ì—¬ê¸°ì— ì›¹ í›… URLì„ ë„£ìœ¼ë©´ ëœë‹¤.
    receivers:
    - name: slack-notifier
      slack_configs:
      - channel: #monitoring
        send_resolved: true
        title: '[{{.Status | toUpper}}] {{ .CommonLabels.alertname }}'
        text: >-
          *Description:* {{ .CommonAnnotations.description }}
    route:
      group_wait: 10s
      group_interval: 1m
      repeat_interval: 5m
      receiver: slack-notifier
```

`k apply -f alert-notifier.yaml`

ì»¨í”¼ê·¸ë§µ ì–´í”Œë¼ì´ í›„ helmìœ¼ë¡œ install í•œë‹¤.
ì•ì˜ ë°°í¬ì™€ ë§ˆì°¬ê°€ì§€ë¡œ values.yamlì„ ì°¸ê³ í•´ ì ì ˆí•˜ê²Œ overwriteí•´ì¤€ë‹¤.

```
helm install prometheus prometheus-community/prometheus \
--set pushgateway.enabled=True \
--set alertmanager.enabled=True \
--set nodeExporter.tolerations[0].key=node-role.kubernetes.io/master \
--set nodeExporter.tolerations[0].operator=Exists \
--set nodeExporter.tolerations[0].effect=NoSchedule \
--set alertmanager.service.annotations."service\.beta\.kubernetes\.io/aws-load-balancer-type"=nlb \
--set alertmanager.tolerations[0].key=node-role.kubernetes.io/master \
--set alertmanager.tolerations[0].operator=Exists \
--set alertmanager.tolerations[0].effect=NoSchedule \
--set alertmanager.nodeSelector.key=master \
--set alertmanager.configMapOverrideName=notifier-config \
--set alertmanager.securityContext.runAsGroup=1000 \
--set alertmanager.securityContext.runAsUser=1000 \
--set alertmanager.service.type="LoadBalancer" \
--set alertmanager.persistentVolume.existingClaim="prometheus-alertmanager" \
--set alertmanager.mountPath="/efs/perometheus/alertmanager" \
--set server.tolerations[0].key=node-role.kubernetes.io/master \
--set server.tolerations[0].operator=Exists \
--set server.tolerations[0].effect=NoSchedule \
--set server.nodeSelector.key=master \
--set server.service.annotations."service\.beta\.kubernetes\.io/aws-load-balancer-type"=nlb \
--set server.persistentVolume.existingClaim="prometheus-server" \
--set server.mountPath="/efs/perometheus/server" \
--set server.securityContext.runAsGroup=1000 \
--set server.securityContext.runAsUser=1000 \
--set server.service.type="LoadBalancer" \
--set server.storage.tsdb.path="/efs/perometheus/server"
```

### Overwrite Summary
>
prometheus-alertmanager, prometheus-serverëŠ” ë§ˆìŠ¤í„° ë…¸ë“œì— ì˜¬ë¦°ë‹¤.
nodeExporterëŠ” ëª¨ë“  ë…¸ë“œì— ì˜¬ë¦°ë‹¤.
alertmanger, serverëŠ” efsì— ë§ˆìš´íŠ¸í•œë‹¤.
nlb typeìœ¼ë¡œ alertmanager, serverë¥¼ ì™¸ë¶€ì— ë…¸ì¶œí•œë‹¤.
SecurityContext ì„¤ì •ì„ í•´ì¤€ë‹¤.(runAsUser, runAsGroup)



## 4. í”„ë¡œë©”í…Œìš°ìŠ¤ì—ì„œ ì•ŒëŒ ê·œì¹™ ë§Œë“¤ê¸°

ì–¼ëŸ¿ë§¤ë‹ˆì €ë¥¼ ë°°í¬í•œë‹¤ê³  ì–¼ëŸ¿ì´ ê°€ëŠ”ê²Œ ì•„ë‹ˆë‹¤. ì–¼ëŸ¿ì´ ê°€ê¸° ìœ„í•œ ê·œì¹™ì„ ì„¤ì •í•´ì¤˜ì•¼ í•œë‹¤.

ì¸ìŠ¤í„´ìŠ¤ê°€ ë‹¤ìš´ ë˜ì—ˆì„ ë•Œ ì•ŒëŒì„ ì£¼ëŠ” ë£°ì„ ë§Œë“¤ì–´ë³¸ë‹¤.

![](https://velog.velcdn.com/images/hyunshoon/post/6867f856-3688-4c2a-b766-1db04d0dcc47/image.png)

`vi rules.yaml`

```
groups:
- name: AllInstances
  rules:
  - alert: InstanceDown
    # Condition for alerting
    expr: up == 0
    for: 1m
    # Annotation - additional informational labels to store more information
    annotations:
      title: 'Instance {{ $labels.instance }} down'
      description: '{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 1 minute.'
    # Labels - additional labels to be attached to the alert
    labels:
      severity: 'critical'
```
ì¸ìŠ¤í„´ìŠ¤ ì¤‘ í•˜ë‚˜ë¼ë„ 1ë¶„ ë™ì•ˆ down ë  ê²½ìš° ì•ŒëŒì´ ë°œë™ëœë‹¤. 

rules.yml íŒŒì¼ì„ alert-notifier.ymlì— ì—°ê²°í•˜ê³  ì•ŒëŒ êµ¬ì„±ì„ ì¶”ê°€í•´ì•¼í•œë‹¤.

```
apiVersion: v1
kind: ConfigMap
metadata:
  annotations:
    meta.helm.sh/release-name: prometheus
    meta.helm.sh/release-namespace: default
  labels:
    app: prometheus
    app.kubernetes.io/managed-by: Helm
    chart: prometheus-16.0.0
    component: alertmanager
    heritage: Helm
    release: prometheus
  name: prometheus-notifier-config
  namespace: default
data:
  alertmanager.yml: |
    global:
      slack_api_url: https://hooks.slack.com/services/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 #ì—¬ê¸°ì— ì›¹ í›… URLì„ ë„£ìœ¼ë©´ ëœë‹¤.
    receivers:
    - name: slack-notifier
      slack_configs:
      - channel: #monitoring
        send_resolved: true
        title: '[{{.Status | toUpper}}] {{ .CommonLabels.alertname }}'
        text: >-
          *Description:* {{ .CommonAnnotations.description }}
    route:
      group_wait: 10s
      group_interval: 1m
      repeat_interval: 5m
      receiver: slack-notifier
      # Rules and alerts are read from the specified file(s)
    rule_files:
      - rules.yml
```

`k apply -f alert-notifier.yml`

ruleì„ ì¶”ê°€í•œ ì»¨í”¼ê·¸ë§µì„ ì¬ ë°°í¬ í–ˆìœ¼ë‹ˆ í”„ë¡œë©”í…Œìš°ìŠ¤ë¥¼ ì¬ì„¤ì¹˜ í•œë‹¤.

## 5. Unexpected Trouble - zsh

ì´ì „ë¶€í„° helm install ì„ í•´ì¤„ ë•Œ ì•„ë˜ì™€ ê°™ì€ ì—ëŸ¬ê°€ ëœ¨ë©° ì„¤ì¹˜ê°€ ë˜ì§€ ì•Šì•˜ë‹¤.

```
zsh: no matches found: nodeExporter.tolerations[0].key=node-role.kubernetes.io/master
```

ê·¸ëŸ¬ë‹¤ ì–´ëŠ ìˆœê°„ í•´ê²°ì´ ë˜ì—ˆëŠ”ë°, ì•Œê³ ë³´ë‹ˆ AWS EC2 ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë‚ ë¦¬ê³  ë‹¤ì‹œ ë§Œë“œëŠ” ê³¼ì •ì—ì„œ zshì„ ì„¤ì¹˜í•˜ê¸° ë²ˆê±°ë¡œì›Œ ê¸°ë³¸ ê°’ì¸ bashë¥¼ ì¨ì„œ ëœ ê²ƒì´ì—ˆë‹¤.

ì¦‰, zshì—ì„œ ì•„ë˜ ì„¤ì¹˜ê°€ ì§„í–‰ë˜ì§€ ì•ŠëŠ”ë‹¤. ì‰˜ì˜ ì°¨ì´ë¡œ ì„¤ì¹˜ê°€ ë˜ì§€ ì•Šì•˜ì„ê±°ë¼ëŠ” ìƒê°ì„ í•˜ì§€ ëª»í•´ì„œ values.yaml íŒŒì¼ì„ í™•ì¸í•˜ë©° í—¤ë§¸ë‹¤.

ê²°ê³¼ì ìœ¼ë¡œ zsh ì€ square-bracket ì„ ì“¸ ë•Œ ì•„ë˜ì™€ ê°™ì´ back slashë¥¼ ë„£ì–´ì¤˜ì•¼ í•œë‹¤.

```
helm install prometheus prometheus-community/prometheus \
--set pushgateway.enabled=True \
--set alertmanager.enabled=True \
--set nodeExporter.tolerations\[0\].key=node-role.kubernetes.io/master \
--set nodeExporter.tolerations\[0\].operator=Exists \
--set nodeExporter.tolerations\[0\].effect=NoSchedule \
--set alertmanager.service.annotations."service\.beta\.kubernetes\.io/aws-load-balancer-type"=nlb \
--set alertmanager.tolerations\[0\].key=node-role.kubernetes.io/master \
--set alertmanager.tolerations\[0\].operator=Exists \
--set alertmanager.tolerations\[0\].effect=NoSchedule \
--set alertmanager.nodeSelector.key=master \
--set alertmanager.configMapOverrideName=notifier-config \
--set alertmanager.securityContext.runAsGroup=1000 \
--set alertmanager.securityContext.runAsUser=1000 \
--set alertmanager.service.type="LoadBalancer" \
--set alertmanager.persistentVolume.existingClaim="prometheus-alertmanager" \
--set alertmanager.mountPath="/efs/perometheus/alertmanager" \
--set server.tolerations\[0\].key=node-role.kubernetes.io/master \
--set server.tolerations\[0\].operator=Exists \
--set server.tolerations\[0\].effect=NoSchedule \
--set server.nodeSelector.key=master \
--set server.service.annotations."service\.beta\.kubernetes\.io/aws-load-balancer-type"=nlb \
--set server.persistentVolume.existingClaim="prometheus-server" \
--set server.mountPath="/efs/perometheus/server" \
--set server.securityContext.runAsGroup=1000 \
--set server.securityContext.runAsUser=1000 \
--set server.service.type="LoadBalancer" \
--set server.storage.tsdb.path="/efs/perometheus/server" \
--set serverFiles.alerting_rules.yml=alerting_rules.yml \
```

## 6. Trouble: CrashLoopBackOff


ì¬ì„¤ì¹˜ í›„ pod describe í•´ë³´ë‹ˆ crashLoopBackOffì— ê°‡í˜€ìˆë‹¤.
```
root@ip-10-0-3-181:~/prometheus# k get pod
NAME                                             READY   STATUS             RESTARTS   AGE
grafana-645d644bf6-jr7mw                         1/1     Running            0          10h
prometheus-alertmanager-7f88dfcffb-pfrfx         1/2     CrashLoopBackOff   5          3m27s

```
ì´ëŸ°ê²½ìš° ì»¨í…Œì´ë„ˆ ë¡œê·¸ë¥¼ ë³´ë©´ ìì„¸íˆ ì•Œ ìˆ˜ ìˆë‹¤.

```
root@ip-10-0-3-181:~/prometheus# k logs prometheus-alertmanager-7f88dfcffb-pfrfx -c prometheus-alertmanager
ts=2022-11-21T12:57:00.736Z caller=main.go:231 level=info msg="Starting Alertmanager" version="(version=0.24.0, branch=HEAD, revision=f484b17fa3c583ed1b2c8bbcec20ba1db2aa5f11)"
ts=2022-11-21T12:57:00.736Z caller=main.go:232 level=info build_context="(go=go1.17.8, user=root@265f14f5c6fc, date=20220325-09:31:33)"
ts=2022-11-21T12:57:00.799Z caller=coordinator.go:113 level=info component=configuration msg="Loading configuration file" file=/etc/config/alertmanager.yml
ts=2022-11-21T12:57:00.799Z caller=coordinator.go:118 level=error component=configuration msg="Loading configuration file failed" file=/etc/config/alertmanager.yml err="yaml: unmarshal errors:\n  line 17: field rule_files not found in type config.plain"
```

alert-notifier.yml 17 ë²ˆ ì§¸ ì¤„ì´ ë¬¸ì œ ì¸ê²ƒ ê°™ë‹¤. config.plain ì— rule_files íƒ€ì…ì´ ì—†ë‹¨ë‹¤.

ì»¨í”¼ê·¸ë§µì„ ë§Œë“¤ ë•Œ rule_filesë¥¼ ë„£ì–´ì£¼ëŠ”ê²Œ ì•„ë‹Œ ê²ƒ ê°™ë‹¤.

ì»¨í”¼ê·¸ë§µì— ruleì„ ì„¤ì •í•˜ì§€ ë§ê³  prometheusë¥¼ ë°°í¬í•  ë•Œ overwriteë¥¼ í•˜ëŠ”ê²Œ ë§ëŠ” ê²ƒ ê°™ë‹¤. values.yamlì„ ì°¸ê³ í•´ë³´ì.

![](https://velog.velcdn.com/images/hyunshoon/post/09ab7e57-a5f3-429c-a07f-3630fd298e89/image.png)

prometheus.yml ì€ alerting_rulesë¥¼ ê·œì¹™ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤.

![](https://velog.velcdn.com/images/hyunshoon/post/78b2cfe1-3fcb-494d-9115-4767ba753188/image.png)

alerting_rules.yml ì€ serverFiles í•˜ìœ„ ëª©ë¡ì´ë¯€ë¡œ ì—¬ê¸°ì—ë‹¤ê°€ overwriteë¥¼ í•´ì¤€ë‹¤.

```
elm install prometheus prometheus-community/prometheus \
--set pushgateway.enabled=True \
--set alertmanager.enabled=True \
--set nodeExporter.tolerations\[0\].key=node-role.kubernetes.io/master \
--set nodeExporter.tolerations\[0\].operator=Exists \
--set nodeExporter.tolerations\[0\].effect=NoSchedule \
--set alertmanager.service.annotations."service\.beta\.kubernetes\.io/aws-load-balancer-type"=nlb \
--set alertmanager.tolerations\[0\].key=node-role.kubernetes.io/master \
--set alertmanager.tolerations\[0\].operator=Exists \
--set alertmanager.tolerations\[0\].effect=NoSchedule \
--set alertmanager.nodeSelector.key=master \
--set alertmanager.configMapOverrideName=notifier-config \
--set alertmanager.securityContext.runAsGroup=1000 \
--set alertmanager.securityContext.runAsUser=1000 \
--set alertmanager.service.type="LoadBalancer" \
--set alertmanager.persistentVolume.existingClaim="prometheus-alertmanager" \
--set alertmanager.persistentVolume.mountPath="/efs/perometheus/alertmanager" \
--set server.tolerations\[0\].key=node-role.kubernetes.io/master \
--set server.tolerations\[0\].operator=Exists \
--set server.tolerations\[0\].effect=NoSchedule \
--set server.nodeSelector.key=master \
--set server.service.annotations."service\.beta\.kubernetes\.io/aws-load-balancer-type"=nlb \
--set server.persistentVolume.existingClaim="prometheus-server" \
--set server.persistentVolume.mountPath="/efs/perometheus/server" \
--set server.securityContext.runAsGroup=1000 \
--set server.securityContext.runAsUser=1000 \
--set server.service.type="LoadBalancer" \
--set server.storage.tsdb.path="/efs/perometheus/server" \
--set alertmanagerFiles.alertmanager.yml="alertmanager.yml" \
--set serverFiles.alerting_rules.yml="alerting_rules.yml" \
```

## 7. Trouble: íŒŒë“œë„ ì •ìƒì‘ë™í•˜ê³  ëŒ€ì‹œë³´ë“œì—ë„ ì ‘ì† ê°€ëŠ¥í•˜ì§€ë§Œ ì•ŒëŒì´ ì‘ë™í•˜ì§€ ì•ŠëŠ”ë‹¤.

ì˜ì‹¬ë˜ëŠ” ì›ì¸ì´ ë„ˆë¬´ ë§ë‹¤. ì§€ì†ì ìœ¼ë¡œ ì•¼ê¸°ë˜ëŠ” ë¬¸ì œëŠ” --set ìœ¼ë¡œ í•„ë“œë¥¼ overwriteë¥¼ í•˜ëŠ” ê³¼ì •ì—ì„œ ì ìš©ì´ ë˜ì§€ ì•ŠëŠ” ê²½ìš°ë“¤ì´ ìì£¼ ë°œìƒí•œë‹¤. ì´ ë¶€ë¶„ì´ ë°°í¬ ê³¼ì •ì—ì„œ ì†ë„ë¥¼ ë”ë””ê²Œ ë§Œë“œëŠ” ì ì´ë‹¤.

ë”°ë¼ì„œ, overwirteë¥¼ í•˜ì§€ ì•Šê³  values.yaml íŒŒì¼ì„ ì§ì ‘ ìˆ˜ì •í•œë‹¤.

í•œë°”íƒ• ë””ë²„ê¹… í›„ install ì— ì„±ê³µ. ìì˜í•œ ì—ëŸ¬ë“¤ì€ ìƒëµí•œë‹¤.

`helm install promethes ./prometheus`


### ì˜ì‹¬ë˜ëŠ” ì›ì¸

1. alertmanager target IP

2. Routing tree

3. rules ìœ„ì¹˜

4. configMap 


## 8. Alert Test

![](https://velog.velcdn.com/images/hyunshoon/post/f2bf5f1b-d4ea-43a9-bb70-fa3b718bc4e3/image.png)
 
ì •ìƒ ì‘ë™ ìƒíƒœ


![](https://velog.velcdn.com/images/hyunshoon/post/84ebe949-8b34-4a7f-a1ef-acf04031c8a3/image.png)

worker ë…¸ë“œ í•˜ë‚˜ ì¤‘ì§€ì‹œì¼œë³¸ë‹¤.

![](https://velog.velcdn.com/images/hyunshoon/post/fbfb2aff-875e-4196-a4b5-18f1a8639c91/image.png)

pending ìƒíƒœ

![](https://velog.velcdn.com/images/hyunshoon/post/a9d631b3-bbd2-4aca-88f8-7746a770f8de/image.png)

firing ì„±ê³µ!



## 9. Trouble 4 - slack webhookì€ ë˜ì§€ ì•ŠìŒ


![](https://velog.velcdn.com/images/hyunshoon/post/fa98c558-afa4-46ea-bbba-1dc2c6eb619d/image.png)

í•˜ì§€ë§Œ slack ì€ ì ì í•˜ë‹¤ ğŸ¤£


1. route receiver ê°€ default ë¡œ ì„¤ì •ë˜ì–´ìˆì—ˆê³  ìœ„ì™€ ê°™ì´ ìˆ˜ì •í–ˆë‹¤. -> ì—¬ì „íˆ ì•ˆëŒ

![](https://velog.velcdn.com/images/hyunshoon/post/41aeed46-6582-44f9-bb97-9ef1aab79559/image.png)


2. ìˆ˜ì‹  ì›¹í›… url ì²´í¬: ì›¹í›… urlì´ ì´ˆê¸°ì— copyí•œ ê²ƒê³¼ ë‹¬ë¼ì ¸ìˆì—ˆë‹¤. ìˆ˜ì •. -> ì—¬ì „íˆ ì•ˆëŒ


3. API TEST

`curl -X POST -H 'Content-type: application/json' --data '{"text":"Hello, World!"}' <web_hook url>`

![](https://velog.velcdn.com/images/hyunshoon/post/fc8a4dcd-d13d-4d37-82ce-05945787f27b/image.png)

API ëŠ” ë¬¸ì œ ì—†ë‹¤.

5. alertmanager.yml ìˆœì„œ -> ê³µì‹ ë¬¸ì„œ ë³´ê³  ì œëŒ€ë¡œ ìˆ˜ì •

6. configmap issue

```shell
 âš¡ root@ip-10-0-3-181 î‚° ~/prometheus î‚° k logs prometheus-alertmanager-557665ccf6-hwkb2 -c prometheus-alertmanager
ts=2022-11-23T02:13:14.108Z caller=main.go:231 level=info msg="Starting Alertmanager" version="(version=0.24.0, branch=HEAD, revision=f484b17fa3c583ed1b2c8bbcec20ba1db2aa5f11)"
ts=2022-11-23T02:13:14.108Z caller=main.go:232 level=info build_context="(go=go1.17.8, user=root@265f14f5c6fc, date=20220325-09:31:33)"
ts=2022-11-23T02:13:14.286Z caller=coordinator.go:113 level=info component=configuration msg="Loading configuration file" file=/etc/config/alertmanager.yml
ts=2022-11-23T02:13:14.287Z caller=coordinator.go:126 level=info component=configuration msg="Completed loading of configuration file" file=/etc/config/alertmanager.yml
ts=2022-11-23T02:13:14.295Z caller=main.go:535 level=info msg=Listening address=:9093
ts=2022-11-23T02:13:14.296Z caller=tls_config.go:195 level=info msg="TLS is disabled." http2=false
ts=2022-11-23T02:19:23.588Z caller=dispatch.go:354 level=error component=dispatcher msg="Notify for alerts failed" num_alerts=3 err="slack-notifier/slack[0]: notify retry canceled due to unrecoverable error after 1 attempts: channel \"#monitoring\": unexpected status code 403: invalid_token"
ts=2022-11-23T02:20:23.496Z caller=dispatch.go:354 level=error component=dispatcher msg="Notify for alerts failed" num_alerts=5 err="slack-notifier/slack[0]: notify retry canceled due to unrecoverable error after 1 attempts: channel \"#monitoring\": unexpected status code 403: invalid_token"

```
![](https://velog.velcdn.com/images/hyunshoon/post/57e466da-d7e2-488a-aed5-3a4f64b9df60/image.png)

configmap overridingì„ í•˜ê³  ìˆì—ˆë‹¤. 


2,000 ì¤„ì´ ë„˜ëŠ” values.yaml ì„ ìˆ˜ì •í•˜ë‹¤ ë³´ë‹ˆ ì¼ì „ì— configMapOverriding ë¶€ë¶„ì— ì»¨í”¼ê·¸ë§µì„ ì—°ê²°í•´ì¤€ ê²ƒì„ ë†“ì³¤ë‹¤. ìˆ˜ì •í–ˆë”ë‹ˆ ìµœì¢…ì ìœ¼ë¡œ ìŠ¬ë™ì—ì„œ ì•ŒëŒì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆë‹¤.

![](https://velog.velcdn.com/images/hyunshoon/post/c4e6ba57-bfed-494c-a7d0-ed4e2d470f9e/image.png)

í…ŒìŠ¤íŠ¸ ì„±ê³µ!

![](https://velog.velcdn.com/images/hyunshoon/post/6736a96c-7c52-4a58-8bf0-30cfdbe71be3/image.gif)



## 10. ì‹œê°„ì´ ê±¸ë¦° ìš”ì¸

1. prometheus-alertmanagerì™€ prometheus-serverëŠ” ê°ê° í”„ë¡œë©”í…Œìš°ìŠ¤ ì»´í¬ë„ŒíŠ¸ë‹¤. í”„ë¡œë©”í…Œìš°ìŠ¤ ê²½ë³´ì‹œìŠ¤í…œ ì„¤ì •ì„ ìœ„í•´ alertmanager inner line(values.yml ì— alertmanager ì™€ server lineì´ êµ¬ë³„ ë˜ì–´ ìˆë‹¤.) ë‚´ë¶€ë§Œì„ ìˆ˜ì •í•˜ë©´ ëœë‹¤ê³  ìƒê°í–ˆë‹¤.

  í•˜ì§€ë§Œ, ê³µë¶€ë¥¼ í•´ë³´ë‹ˆ alertmanagerëŠ” alert**"manager"**ì´ë‹¤. ì¦‰, ì•ŒëŒì„ í”„ë¡œë©”í…Œìš°ìŠ¤ ì„œë²„ì—ì„œ ì „ë‹¬ ë°›ëŠ”ë‹¤. ì•Œë¦¼ì„ ë§¤ë‹ˆì§• í•˜ëŠ” ì—­í• ì´ê³ , ì•Œë¦¼ì„ ë§Œë“œëŠ” ì—­í• ì€ í”„ë¡œë©”í…Œìš°ìŠ¤ ì„œë²„ì´ê¸° ë•Œë¬¸ì— í”„ë¡œë©”í…Œìš°ìŠ¤ í”„ë¡œì„¸ìŠ¤ë¥¼ ì˜ ì•Œê³  ìˆì—ˆë‹¤ë©´ ë³´ë‹¤ ë¹ ë¥´ê²Œ í”„ë¡œë©”í…Œìš°ìŠ¤ ì„œë²„ë„ ì†ë´ì•¼ í•œë‹¤ëŠ” ê²ƒì„ ëˆˆì¹˜ì±˜ì„ ê²ƒì´ë‹¤.
  
  ë˜í•œ, values.yaml ë§ˆì§€ë§‰ ë¶€ë¶„ì— prometheus.yml ê³¼ serverFilesì— ëŒ€í•œ ì„¤ì •ì´ ìˆì—ˆë‹¤. ê²°êµ­ ì „ì²´ ë¼ì¸ì„ ì „ë¶€ ë´ì•¼í–ˆëŠ”ë° ê²½ìš°ì˜ ìˆ˜ê°€ ë§ì•„ ë’¤ëŠ¦ê²Œ í™•ì¸í–ˆë‹¤.
  

2. ì»¨í…Œì´ë„ˆê°€ ìƒì„±ë˜ë©° ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì— ìƒì„±ë˜ëŠ” íŒŒì¼ê³¼ ì»¨í…Œì´ë„ˆ ì™¸ë¶€(í˜¸ìŠ¤íŠ¸)ì—ì„œ ê°€ì ¸ì˜¤ëŠ” íŒŒì¼ì„ í˜¼ë™í•˜ì—¬ ë‹¤ëŸ‰ì˜ ì‚½ì§ˆì„ í–ˆë‹¤. ì»¨í…Œì´ë„ˆ ë™ì‘ì— ëŒ€í•œ ê°œë…ì„ íŠ¼íŠ¼í•˜ê²Œ í•  í•„ìš”ì„±ì„ ëŠê¼ˆë‹¤.

3. ìš°ë¦¬ë§Œì˜ í™˜ê²½ì— ë°°í¬í•˜ë ¤ë©´ ì»¤ìŠ¤í„°ë§ˆì´ì§•ì„ í•´ì•¼í•˜ê³ , ë¬¸ë²•ê³¼ í”„ë¡œì„¸ìŠ¤ì— ëŒ€í•´ ê³µë¶€í•˜ëŠ” ì‹œê°„ì´ ì†Œìš”ë˜ëŠ”ê±´ ë‹¹ì—°í•œ ë“¯



Reference

- https://prometheus.io/docs/alerting/latest/alertmanager/
- https://prometheus.io/docs/alerting/latest/configuration/
- https://awesome-prometheus-alerts.grep.to/rules.html#host-and-hardware
- https://grafana.com/blog/2020/02/25/step-by-step-guide-to-setting-up-prometheus-alertmanager-with-slack-pagerduty-and-gmail/
- https://kinopyo.com/en/blog/escape-square-bracket-by-default-in-zsh








