### 고가용성(HA)
전체 시스템에 대한 개념이다. 사람이 개입하지 않아도 시스템이 항상 작동하며 액세스 가능하며 가동 중지를 최소화하도록 보장하는 것이다. (장애가 발생하더라도 아주 짧은 시간이며, 자동으로 복구)

즉, 서버와 네트워크, 프로그램 등의 시스템이 오랜 기간동안 지속적으로 정상 운영이 가능한 성질을 말하며, 고장나도 바로 복구해서 서비스를 지속할수 있는 능력을 말한다 

단, 복구를 위한 약간의 장애시간도 포함한다.

고가용성은 여러 대의 서버, 각 리전 내에 여러 개의 가용 영역, 여러 개의 리전, 내결함성 서비스에 대한 액세스를 확보하여 원하는 대로 사용할 수 있다.


> AWS 고가용성 도구 - 특정 서비스가 고가용성을 제공할 때 도움이 되는 방법에 대해 살펴보자
>
> - ELB - 지연 시간이 길거나 서버가 과다 사용되는 경우 이를 알리는 트리거로 동작한다.
> - EIP - 애플리케이션의 내결함성을 향상시킬 때 유용하다. 인스턴스가 실패하더라도 클라이언트가 애플리케이션에 액세스할 수 있으므로 고가용성이 보장된다.
> - Route 53 - 단순 라우팅, 지연 시간에 따른 라우팅, 상태확인, DNS 장애 조치, 지리 위치 라우팅 지원하기 위해 개발 되었으며, 이 모든 특성을 통해 고객 대면 애플리케이션의 가용성이 증가한다.
> - Auto Scaling & CloudWatch- 설정된 임계값을 통과한 지표가 있는 경우 Auto Scaling과 함께 CloudWatch가 자동으로 확장되어 아키텍처의 고가용성을 보장할 수 있다.
> - 여러 AZ

----
### 내결함성/장애내구성
하드웨어 오류가 발생 했을때 데이터 무결성을 유지하는 컴퓨토 하드웨어나 소프트웨어의 기능

즉, 시스템의 일부 구성요소에 장애 상화에도 서비스를 지속할 수 있는 능력을 의미한다.

여기서 조심해야할 것은 장애를 떠안은채 서비스를 지속한다는 개념이 아니다.(서비스에 장애가 있으면 누가 안심할까?)

장애가 있어도 다른 가용영역(AZ)로 연결을 시킴으로서 해결하는 즉, 간접적으로 우회해서 해결할 수 있는 능력을 말한다. (장애를 고치는 것이 아니다.)

그렇기 때문에, 장애 상황에 영향을 받지 않는 아키텍쳐가 필요하다.

> AWS 내결함성 도구
> 
> - SQS - 내결함성 애플리케이션의 백본으로 사용할 수 있으며, 이는 매우 안정적인 분산 메시징 시스템이다. 대기열을 항시 사용 가능하도록 도와준다.
> - S3 - 내구성과 결함성이 뛰어난 데이터 스토리지이며, 리전 내 여러 시설에서 각 디바이스의 모든 데이터를 중복 저장한다. 장애가 발생하더라도 모든 정보에 액세스할 수 있다.
> - RDS - 중요한 DB의 안정성을 향상시키는 몇 가지 기능을 제공하여 고가용성과 내결함성을 제공한다. 자동 백업, 스냅샷, 여러 가용 영역 지점을 포함한다.

--- 

### 고가용성 & 장애내구성 조합
![image](https://user-images.githubusercontent.com/88362207/205246542-734d4146-80e2-451d-925f-ef0f679aac52.png)

고가용성과 내결함성 둘 다를 확보하는 것은 고비용/복잡한 구조일 것이다.

따라서 상황에 따라 어느것을 우선시해 비용을 줄이는 것이 중요한데, 만일 의료시스템 같은 경우엔 잠시 동안의 서비스 장애도 치명적인 결과를 불러올 수 있기 때문에 고비용/복잡한 구조여도 장애 내구성을 확보하는 것이 옳다.

하지만 장애내구성을 확보할 필요가 없는 서비스는 비용을 줄여 고가용성만 확보하는 식으로 설계한다.

고가용성과 장애내구성의 개념을 정확히 알고 잘 조합하여 상황에 맞는 아키텍쳐 설계가 가장 중요하다.

자동차와 비행기를 예를 들어 설명 해 보겠다.
#### 고가용성 X / 장애내구성 X
> - 자동차의 타이어가 터지면 운전이 불가능해진다
#### 고가용성 O / 장애내구성 X
> - 스페어 타이어를 가지고 있는 자동차는 타이어 하나가 터지더라도 운전자가 내려 수리후 운전이 가능하다.
> - 즉, 장애가 생겨도 장애를 복구하여 서비스를 지속하는 고가용성에 해당한다.
> - 단, 타이어가 터져 수리하는 동안은 운전이 불가능하기 때문에 장애내구성은 확보 할 수 없다.
#### 고가용성 O / 장애내구성 O
> - 비행기 같은 경우 엔진이 하나 터지터라도 여분의 엔진 3개가 이어서 계속 작동하도록 설계되어있다.
> - 즉, 엔진이 터지더라도 비행이 계속 가능하다.
> - 이것은 장애가 발생하여도 서비스를 지속함으로 고가용성과 장애내구성을 확보 했다고 말할 수 있다.
> - 모두 비행기처럼 설계하면 좋지만 비용이 가장 큰 문제이다.






---

### 탄력성
용량 요구사항에 대해 신경쓰지 않고 자동화된 확장 및 축소하는 것 

> - 수요에 따라 컴퓨팅파워 또는 용량을 확장하거나 축소 할 수 있는 능력(확장성은 말 그대로 확장만한다.) 
> - 불필요한 자원을 사용하지 않고 비용 최적화에 필수적인 능력
> - 트래픽 급증 시 웹 서버 수 자동으로 증가시키거나, 트래픽이 줄어들 때 DB 쓰기 용량 감소(IOPS : Input/Output Opereations Per Second)
> - 아키텍쳐 전반에 걸친 일상적인 수요 변동 처리
> - 시간 기반 탄력성 : 리소스가 사용되지 않을 때 리소스 끄기
> - 볼륨 기반 탄력성 : 수용 강도에 맞게 규모 조정

---

### 확장성
> - 쉽고 빠르게 규모를 늘릴 수 있는 능력
> - 주로 수요에 따라 컴퓨팅 파워 또는 용량 확장
> - 예를 들면, user가 한명일 때 서버 하나, user가 여러명으로 늘어날때는 자동으로 서버 scale up

---
### 장애허용
> - 고가용성과 다르게 장애가 발생하더라도 서비스의 중단없이 장애를 가진채 계속 서비스되는 시스템을 의미한다.

---
###  DR(Disaster Recovery)
> - 재해 복구는 장애 상황을 복구하는 것이다.
> - 망가졌을때 수리한다는 개념으로 앞에서 설명한 고가용성과 장애내구성과는 다르고 상관없는 개념이다.
> - 재해(재앙) 복구 시스템. IDC별, 전산신별, 지점별 등 지역적으로 분리된 서버들에 대해 무정지 서비스 가능. 갑작스런 네트워크의 단절, 네트워크 노드의 불안정, 장비의 다운,정전 등으로 인한 문제 해결
> - DR은 화재, 홍수, 지진 등 천재지변 등 예상치 못한 사태에 데이터센터에 장애가 발생했을 때를 대비해 원거리에 복제 시스템을 두는 것을 말한다.

AWS의 한국 region이 멈춘다면 재해복구에 대한 필요성을 볼 수 있다.

국내 인터넷 기업은 DR에 대해 소극적인 편이며, DR보다는 고가용성(HA)에 주로 투자를 한다. HA는 특정 시스템에 장애가 났을 때 다른 시스템이 이를 받아 서비스를 계속 하는 기술이며, HA는 같은 지역 내에서 시스템을 이중화, 삼중화 한다. AWS 장애처럼 지역 전체 시스템에 문제가 발생했을 때는 HA가 할 수 있는 일이 없다. 

많은 전문가들은 AWS 장애 이후 '멀티 리전 DR(복수의 리전에 DR 시스템을 두는 것)’의 중요성을 이야기 한다. 한국 리전에서 장애가 발생한다면, 일본 등 다른 리전을 이용하는 기업은 장애가 발생하지 않으며, 복수 리전을 이용했다면 큰 피해는 입지 않았을 것이라는 의미이다.

장애를 겪은 A 업체 관계자들은 멀티 리전 DR이 필요하다는 것은 알지만, 바용이 두 배로 들기 때문에 당장 하기 어렵다고 말한다.

B 업체 관계자는 DR무용론을 이야기한다. 이 관계자는 “이번에 한국 리전 전체가 다운됐는데 다른 리전에 DR이 돼 있더라고 하더라도 다른 리전에서 서비스 가동되기까지 시간이 많이 걸린다”면서 “다른 리전에서 서비스를 생성하는 중간에 한국 리전이 복구됐을 가능성이 높다”고 설명한다.

C 업체는 멀티 리전은 아니지만 AZ( Availability Zone, 가용 영역) 수준의 DR을 하고 있다. AZ는 한 리전에 속해 있지만 물리적으로 분리된 데이터센터다. 하나의 리전은 복수의 AZ로 구성된다. 

C 업체 관계자는 “장애 발생에 대비하기 위해 (서울 리전) 두 개의 AZ에 서비스를 병행해 운영하고 있었다”면서 “그럼에도 불구하고 이번 장애는 서울 리전 전체에 여파를 미쳤기 때문에 어쩔 수 없었다”고 설명했다.

이 관계자는 “다른 리전을 안 쓴 이유는 한국 리전보다 응답시간이 조금 더 오래 걸리는 부분이 있어서, 서비스를 운영하는 시스템 사이에 동기화할 정보들이 많이 있는 경우 시스템 부하 문제가 있을 수 있기 때문이며, 이번을 계기로, 일부 비용을 감수하고라도 향후 도쿄 리전을 병행해 이용하는 것을 내부 검토 중”이라고 말했다.

---

### 다중 AZ 전략

![image](https://user-images.githubusercontent.com/88362207/205271680-0455d29b-c3fe-4f97-baaa-ee15df95a1ec.png)

> 모든 AWS 리전 은 여러 가용 영역(AZ)으로 구성된다. 각 AZ는 별개의 고유한 지리적 위치에 위치한 하나 이상의 데이터 센터로 구성되는데, 이렇게 하면 단일 이벤트가 둘 이상의 AZ에 영향을 미칠 위험이 크게 줄어든다. 
>
> 따라서 정전, 홍수 및 기타 국지적 중단과 같은 이벤트를 견디도록 DR 전략을 설계하는 경우 AWS 리전 내에서 다중 AZ DR 전략을 사용하면 필요한 보호를 제공할 수 있다. (가용성 영역은 각 지역에서 격리된 여러 데이터 센터이다.)
> 
> 즉, 현재 서울의 AZ는 2개이고 한개의 AZ가 장애가 나더라도 다른 AZ를 통해 서비스가 가능한 구조이다. 이런 위험 분산 측면에서 AZ가 최소한 2개이상으로 구성되어 있다.

---
# 시나리오 

한 기업에서 다음과 같은 요구 사항을 받는다.
1. 정전, 홍수 및 기타 국지적 중단과 같은 이벤트로 장애가 발생하여 인프라(Availability Zone)에 장애가 생겨 서비스 제공에 문제가 발생하면 안된다.
2. 완전한 권한이 AWS 사용자에 있어야한다. (모든 책임과 권한을 사용자가 가진다.)
3. k8s 인프라 관리를 직접 할 수 있어야한다.

위와 같은 요구 사항을 받고 고가용성을 위해 다중 AZ 전략을 이용하여 AWS Cloud 아키텍처를 설계하고 인프라를 구축하였다.

이후 개발자가 이용할 수 있는 인프라 구축 이라는 추가적인 니즈를 받고 해결하기 위해 자동화 인프라를 구축한다. 

### 목적 (문제 정의)


<!-- 뭐가 문제인가? - 기사 발췌하여 인용하기 
  1. 존 에러
  2. HA 클러스터 구축 번거로움 -->

정전, 홍수 및 기타 국지적 중단과 같은 이벤트로 장애가 발생하여 인프라(Availability Zone)에 장애가 생겨 서비스 제공에 문제가 발생하면 안된다.

그렇기 때문에 본 프로젝트는 DR 전략을 설계하여, AWS 리전 내에서 다중 AZ DR 전략을 이용해 한개의 AZ에 장애가 발생하더라고 다른 AZ를 통해 서비스가 가능한 구조로 설계한다.

또한, 과한 트래픽으로 인해 제공되는 애플리케이션 서비스가 중단 될 수 있어 무중단 서비스를 제공할 수 있도록 해야한다.

AZ에 장애가 발생하거나 과한 트래픽으로 인해 Master node에 장애가 발생한다면 k8s Cluster에 영향을 미치게 되므로 고가용성 Cluster를 연결시켜 Load Balancing 및 고가용성을 유지할 수 있다.

worker node에 과한 트래픽으로 인해 해당 서비스 pod가 auto scaling을 통해 scale out하게 되고, worker node가 scale out된 pod의 수가 많아 용량이 부족해지게 되면 worker node 또한, auto scaling을 통한 scale out하게 된다.

Amazon EC2를 사용해 k8s를 구축하였기  Kubernetes 인프라를 직접 관리할 수 있다.


### 프로젝트
<!-- 1. 시연 -> 데모영상 -> 주요 장애 케이스 검증
2. 전체 아키텍쳐
3. 주요 어필 포인트 (기술적)
  3.1 인프라 - 스크립트:
             - 인프라 세팅 오토스케일링
  3.2 모니터링
  3.3 CI/CD - 전체 플로우
 -->
### 완성본 to do list











<!-- 
본 프로젝트는 다중 AZ 전략을 사용하여 설계되었다. 
aws의 AZ( Availability Zone, 가용 영역)을 나누어, 각 지역이 다른 지역과 격리되도록 설계하였다. 이는 가능한 최고의 내결함성 및 안정성을 제공한다. 
만약 Availability Zone A가 장애가 발생하였다면, zone A의 master node는 죽게되고, 

 -->

<!-- 
본 프로젝트는 안정적인 클러스터 유지를 위해 아래와 같은 방식으로 아키텍쳐를 설계하였다.

테스트 시나리오는 아래와 같다.
```
aws availability zone
1. auto scaling test (node, pod)
2. master node HA
3. jenkins node
4. monitoring

```
 -->



<!-- 
node scale out test
먼저 노드는 용량이 다 차면 scaling out 한다

pod scale out test
파드는 트래픽이 증가하게 되면 scaling 한다

HA에 의해서 장애 발생시 자동 Fail-Over(Master 승격)를 지원하고 Slave 중 가장 최신의 Slave DB를 Master DB로 승격시켜 고가용성을 유지
먼저 트래픽을 받도록 load balancer로  NLB를 배포하였다.  -->



